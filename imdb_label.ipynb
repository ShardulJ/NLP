{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Shardul Janaskar\\Downloads\\sentiment_labelled\\sentiment labelled sentences\\imdb_labelled.txt\", 'r') as infile, \\\n",
    "     open(r\"C:\\Users\\Shardul Janaskar\\Downloads\\sentiment_labelled\\sentiment labelled sentences\\imdb_labelled_new.txt\", 'w') as outfile:\n",
    "    data = infile.read()\n",
    "    data = data.replace('\"', '')\n",
    "    outfile.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df = pd.read_csv(r'C:\\Users\\Shardul Janaskar\\Downloads\\sentiment_labelled\\sentiment labelled sentences\\imdb_labelled_new.txt',sep = '\\t',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.columns = ['sentence','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      "sentence    1000 non-null object\n",
      "label       1000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "imdb_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = imdb_df['sentence'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvec.fit(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = countvec.transform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3047)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mat\n",
    "y = imdb_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(X,y,test_size = 0.3,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[117  23]\n",
      " [ 66  94]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.84      0.72       140\n",
      "           1       0.80      0.59      0.68       160\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       300\n",
      "   macro avg       0.72      0.71      0.70       300\n",
      "weighted avg       0.73      0.70      0.70       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7033333333333334"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = imdb_df['sentence'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(doc_set):\n",
    "    \"\"\"\n",
    "    Input  : docuemnt list\n",
    "    Purpose: preprocess text (tokenize, removing stopwords, and stemming)\n",
    "    Output : preprocessed text\n",
    "    \"\"\"\n",
    "    # initialize regex tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # create English stop words list\n",
    "    en_stop = set(stopwords.words('english'))\n",
    "    # Create p_stemmer of class PorterStemmer\n",
    "    p_stemmer = PorterStemmer()\n",
    "    # list for tokenized documents in loop\n",
    "    texts = []\n",
    "    # loop through document list\n",
    "    for i in doc_set:\n",
    "        # clean and tokenize document string\n",
    "        raw = i.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        # remove stop words from tokens\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "        # stem tokens\n",
    "        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "        # add tokens to list\n",
    "        texts.append(stemmed_tokens)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = preprocess_data(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = [\" \".join(token) for token in processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv= CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.transform(token).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = imdb_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(X,y,test_size= 0.2,random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomialnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomialnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred= multinomialnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.815"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shardul Janaskar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1], dtype=int64)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,log_reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_dim = X_train.shape[1]\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(10,input_dim = ip_dim,activation = 'relu'))\n",
    "model.add(layers.Dense(2,activation ='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 10)                24100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 24,122\n",
      "Trainable params: 24,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 680 samples, validate on 120 samples\n",
      "Epoch 1/100\n",
      "680/680 [==============================] - 1s 1ms/step - loss: 0.6917 - acc: 0.5676 - val_loss: 0.6824 - val_acc: 0.6833\n",
      "Epoch 2/100\n",
      "680/680 [==============================] - 0s 250us/step - loss: 0.6433 - acc: 0.8294 - val_loss: 0.6398 - val_acc: 0.7667\n",
      "Epoch 3/100\n",
      "680/680 [==============================] - 0s 234us/step - loss: 0.5455 - acc: 0.9044 - val_loss: 0.5512 - val_acc: 0.8583\n",
      "Epoch 4/100\n",
      "680/680 [==============================] - 0s 241us/step - loss: 0.4093 - acc: 0.9397 - val_loss: 0.4714 - val_acc: 0.8500\n",
      "Epoch 5/100\n",
      "680/680 [==============================] - 0s 255us/step - loss: 0.3007 - acc: 0.9515 - val_loss: 0.4074 - val_acc: 0.8833\n",
      "Epoch 6/100\n",
      "680/680 [==============================] - 0s 277us/step - loss: 0.2268 - acc: 0.9559 - val_loss: 0.3688 - val_acc: 0.9000\n",
      "Epoch 7/100\n",
      "680/680 [==============================] - 0s 294us/step - loss: 0.1780 - acc: 0.9647 - val_loss: 0.3411 - val_acc: 0.8750\n",
      "Epoch 8/100\n",
      "680/680 [==============================] - 0s 277us/step - loss: 0.1445 - acc: 0.9706 - val_loss: 0.3225 - val_acc: 0.8583\n",
      "Epoch 9/100\n",
      "680/680 [==============================] - 0s 327us/step - loss: 0.1211 - acc: 0.9721 - val_loss: 0.3099 - val_acc: 0.8750\n",
      "Epoch 10/100\n",
      "680/680 [==============================] - 0s 336us/step - loss: 0.1030 - acc: 0.9779 - val_loss: 0.2997 - val_acc: 0.8833\n",
      "Epoch 11/100\n",
      "680/680 [==============================] - 0s 281us/step - loss: 0.0893 - acc: 0.9794 - val_loss: 0.2925 - val_acc: 0.8833\n",
      "Epoch 12/100\n",
      "680/680 [==============================] - 0s 280us/step - loss: 0.0786 - acc: 0.9853 - val_loss: 0.2860 - val_acc: 0.8917\n",
      "Epoch 13/100\n",
      "680/680 [==============================] - 0s 341us/step - loss: 0.0701 - acc: 0.9882 - val_loss: 0.2836 - val_acc: 0.8917\n",
      "Epoch 14/100\n",
      "680/680 [==============================] - 0s 338us/step - loss: 0.0629 - acc: 0.9882 - val_loss: 0.2807 - val_acc: 0.9000\n",
      "Epoch 15/100\n",
      "680/680 [==============================] - 0s 315us/step - loss: 0.0573 - acc: 0.9897 - val_loss: 0.2804 - val_acc: 0.9000\n",
      "Epoch 16/100\n",
      "680/680 [==============================] - 0s 347us/step - loss: 0.0523 - acc: 0.9897 - val_loss: 0.2796 - val_acc: 0.9000\n",
      "Epoch 17/100\n",
      "680/680 [==============================] - 0s 325us/step - loss: 0.0481 - acc: 0.9897 - val_loss: 0.2783 - val_acc: 0.9000\n",
      "Epoch 18/100\n",
      "680/680 [==============================] - 0s 340us/step - loss: 0.0446 - acc: 0.9897 - val_loss: 0.2797 - val_acc: 0.8917\n",
      "Epoch 19/100\n",
      "680/680 [==============================] - 0s 305us/step - loss: 0.0413 - acc: 0.9897 - val_loss: 0.2806 - val_acc: 0.8917\n",
      "Epoch 20/100\n",
      "680/680 [==============================] - 0s 330us/step - loss: 0.0387 - acc: 0.9897 - val_loss: 0.2809 - val_acc: 0.8917\n",
      "Epoch 21/100\n",
      "680/680 [==============================] - 0s 311us/step - loss: 0.0363 - acc: 0.9912 - val_loss: 0.2857 - val_acc: 0.8750\n",
      "Epoch 22/100\n",
      "680/680 [==============================] - 0s 331us/step - loss: 0.0338 - acc: 0.9912 - val_loss: 0.2879 - val_acc: 0.8750\n",
      "Epoch 23/100\n",
      "680/680 [==============================] - 0s 312us/step - loss: 0.0319 - acc: 0.9897 - val_loss: 0.2891 - val_acc: 0.8833\n",
      "Epoch 24/100\n",
      "680/680 [==============================] - 0s 281us/step - loss: 0.0300 - acc: 0.9912 - val_loss: 0.2928 - val_acc: 0.8750\n",
      "Epoch 25/100\n",
      "680/680 [==============================] - 0s 280us/step - loss: 0.0287 - acc: 0.9912 - val_loss: 0.2970 - val_acc: 0.8833\n",
      "Epoch 26/100\n",
      "680/680 [==============================] - 0s 285us/step - loss: 0.0269 - acc: 0.9912 - val_loss: 0.2998 - val_acc: 0.8833\n",
      "Epoch 27/100\n",
      "680/680 [==============================] - 0s 327us/step - loss: 0.0257 - acc: 0.9912 - val_loss: 0.3048 - val_acc: 0.8917\n",
      "Epoch 28/100\n",
      "680/680 [==============================] - 0s 297us/step - loss: 0.0242 - acc: 0.9926 - val_loss: 0.3053 - val_acc: 0.8833\n",
      "Epoch 29/100\n",
      "680/680 [==============================] - 0s 284us/step - loss: 0.0230 - acc: 0.9926 - val_loss: 0.3107 - val_acc: 0.8833\n",
      "Epoch 30/100\n",
      "680/680 [==============================] - 0s 288us/step - loss: 0.0219 - acc: 0.9926 - val_loss: 0.3126 - val_acc: 0.8833\n",
      "Epoch 31/100\n",
      "680/680 [==============================] - 0s 343us/step - loss: 0.0208 - acc: 0.9926 - val_loss: 0.3194 - val_acc: 0.8833\n",
      "Epoch 32/100\n",
      "680/680 [==============================] - 0s 306us/step - loss: 0.0198 - acc: 0.9941 - val_loss: 0.3229 - val_acc: 0.8833\n",
      "Epoch 33/100\n",
      "680/680 [==============================] - 0s 272us/step - loss: 0.0188 - acc: 0.9941 - val_loss: 0.3293 - val_acc: 0.8917\n",
      "Epoch 34/100\n",
      "680/680 [==============================] - 0s 278us/step - loss: 0.0182 - acc: 0.9941 - val_loss: 0.3310 - val_acc: 0.8917\n",
      "Epoch 35/100\n",
      "680/680 [==============================] - 0s 269us/step - loss: 0.0173 - acc: 0.9956 - val_loss: 0.3360 - val_acc: 0.8917\n",
      "Epoch 36/100\n",
      "680/680 [==============================] - 0s 283us/step - loss: 0.0165 - acc: 0.9956 - val_loss: 0.3425 - val_acc: 0.8917\n",
      "Epoch 37/100\n",
      "680/680 [==============================] - 0s 266us/step - loss: 0.0157 - acc: 0.9956 - val_loss: 0.3478 - val_acc: 0.8917\n",
      "Epoch 38/100\n",
      "680/680 [==============================] - 0s 287us/step - loss: 0.0152 - acc: 0.9956 - val_loss: 0.3536 - val_acc: 0.8917\n",
      "Epoch 39/100\n",
      "680/680 [==============================] - 0s 281us/step - loss: 0.0147 - acc: 0.9956 - val_loss: 0.3584 - val_acc: 0.8833\n",
      "Epoch 40/100\n",
      "680/680 [==============================] - 0s 288us/step - loss: 0.0141 - acc: 0.9956 - val_loss: 0.3650 - val_acc: 0.8833\n",
      "Epoch 41/100\n",
      "680/680 [==============================] - 0s 283us/step - loss: 0.0135 - acc: 0.9956 - val_loss: 0.3709 - val_acc: 0.8750\n",
      "Epoch 42/100\n",
      "680/680 [==============================] - 0s 268us/step - loss: 0.0130 - acc: 0.9956 - val_loss: 0.3754 - val_acc: 0.8750\n",
      "Epoch 43/100\n",
      "680/680 [==============================] - 0s 300us/step - loss: 0.0126 - acc: 0.9971 - val_loss: 0.3844 - val_acc: 0.8750\n",
      "Epoch 44/100\n",
      "680/680 [==============================] - 0s 272us/step - loss: 0.0123 - acc: 0.9971 - val_loss: 0.3847 - val_acc: 0.8750\n",
      "Epoch 45/100\n",
      "680/680 [==============================] - 0s 281us/step - loss: 0.0119 - acc: 0.9971 - val_loss: 0.3952 - val_acc: 0.8750\n",
      "Epoch 46/100\n",
      "680/680 [==============================] - 0s 285us/step - loss: 0.0115 - acc: 0.9971 - val_loss: 0.3997 - val_acc: 0.8750\n",
      "Epoch 47/100\n",
      "680/680 [==============================] - 0s 290us/step - loss: 0.0111 - acc: 0.9971 - val_loss: 0.4053 - val_acc: 0.8750\n",
      "Epoch 48/100\n",
      "680/680 [==============================] - 0s 271us/step - loss: 0.0107 - acc: 0.9971 - val_loss: 0.4160 - val_acc: 0.8750\n",
      "Epoch 49/100\n",
      "680/680 [==============================] - 0s 287us/step - loss: 0.0105 - acc: 0.9971 - val_loss: 0.4203 - val_acc: 0.8750\n",
      "Epoch 50/100\n",
      "680/680 [==============================] - 0s 278us/step - loss: 0.0102 - acc: 0.9971 - val_loss: 0.4270 - val_acc: 0.8750\n",
      "Epoch 51/100\n",
      "680/680 [==============================] - 0s 293us/step - loss: 0.0099 - acc: 0.9971 - val_loss: 0.4297 - val_acc: 0.8750\n",
      "Epoch 52/100\n",
      "680/680 [==============================] - 0s 300us/step - loss: 0.0097 - acc: 0.9971 - val_loss: 0.4374 - val_acc: 0.8750\n",
      "Epoch 53/100\n",
      "680/680 [==============================] - 0s 280us/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.4442 - val_acc: 0.8750\n",
      "Epoch 54/100\n",
      "680/680 [==============================] - 0s 249us/step - loss: 0.0091 - acc: 0.9971 - val_loss: 0.4517 - val_acc: 0.8750\n",
      "Epoch 55/100\n",
      "680/680 [==============================] - 0s 272us/step - loss: 0.0093 - acc: 0.9971 - val_loss: 0.4595 - val_acc: 0.8750\n",
      "Epoch 56/100\n",
      "680/680 [==============================] - 0s 259us/step - loss: 0.0089 - acc: 0.9971 - val_loss: 0.4650 - val_acc: 0.8750\n",
      "Epoch 57/100\n",
      "680/680 [==============================] - 0s 263us/step - loss: 0.0087 - acc: 0.9971 - val_loss: 0.4688 - val_acc: 0.8750\n",
      "Epoch 58/100\n",
      "680/680 [==============================] - 0s 250us/step - loss: 0.0085 - acc: 0.9971 - val_loss: 0.4759 - val_acc: 0.8750\n",
      "Epoch 59/100\n",
      "680/680 [==============================] - 0s 288us/step - loss: 0.0084 - acc: 0.9971 - val_loss: 0.4869 - val_acc: 0.8750\n",
      "Epoch 60/100\n",
      "680/680 [==============================] - 0s 281us/step - loss: 0.0082 - acc: 0.9971 - val_loss: 0.4877 - val_acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "680/680 [==============================] - 0s 249us/step - loss: 0.0081 - acc: 0.9971 - val_loss: 0.4958 - val_acc: 0.8750\n",
      "Epoch 62/100\n",
      "680/680 [==============================] - 0s 246us/step - loss: 0.0079 - acc: 0.9971 - val_loss: 0.4985 - val_acc: 0.8750\n",
      "Epoch 63/100\n",
      "680/680 [==============================] - 0s 322us/step - loss: 0.0078 - acc: 0.9971 - val_loss: 0.5079 - val_acc: 0.8667\n",
      "Epoch 64/100\n",
      "680/680 [==============================] - 0s 249us/step - loss: 0.0075 - acc: 0.9971 - val_loss: 0.5160 - val_acc: 0.8667\n",
      "Epoch 65/100\n",
      "680/680 [==============================] - 0s 238us/step - loss: 0.0073 - acc: 0.9971 - val_loss: 0.5227 - val_acc: 0.8667\n",
      "Epoch 66/100\n",
      "680/680 [==============================] - 0s 233us/step - loss: 0.0073 - acc: 0.9971 - val_loss: 0.5296 - val_acc: 0.8667\n",
      "Epoch 67/100\n",
      "680/680 [==============================] - 0s 228us/step - loss: 0.0072 - acc: 0.9971 - val_loss: 0.5332 - val_acc: 0.8667\n",
      "Epoch 68/100\n",
      "680/680 [==============================] - 0s 234us/step - loss: 0.0071 - acc: 0.9971 - val_loss: 0.5431 - val_acc: 0.8667\n",
      "Epoch 69/100\n",
      "680/680 [==============================] - 0s 246us/step - loss: 0.0070 - acc: 0.9971 - val_loss: 0.5513 - val_acc: 0.8667\n",
      "Epoch 70/100\n",
      "680/680 [==============================] - 0s 235us/step - loss: 0.0068 - acc: 0.9971 - val_loss: 0.5551 - val_acc: 0.8667\n",
      "Epoch 71/100\n",
      "680/680 [==============================] - 0s 230us/step - loss: 0.0067 - acc: 0.9971 - val_loss: 0.5603 - val_acc: 0.8667\n",
      "Epoch 72/100\n",
      "680/680 [==============================] - 0s 252us/step - loss: 0.0067 - acc: 0.9985 - val_loss: 0.5637 - val_acc: 0.8667\n",
      "Epoch 73/100\n",
      "680/680 [==============================] - 0s 230us/step - loss: 0.0069 - acc: 0.9971 - val_loss: 0.5747 - val_acc: 0.8667\n",
      "Epoch 74/100\n",
      "680/680 [==============================] - 0s 243us/step - loss: 0.0065 - acc: 0.9985 - val_loss: 0.5825 - val_acc: 0.8667\n",
      "Epoch 75/100\n",
      "680/680 [==============================] - 0s 249us/step - loss: 0.0064 - acc: 0.9985 - val_loss: 0.5849 - val_acc: 0.8667\n",
      "Epoch 76/100\n",
      "680/680 [==============================] - 0s 237us/step - loss: 0.0064 - acc: 0.9985 - val_loss: 0.5924 - val_acc: 0.8667\n",
      "Epoch 77/100\n",
      "680/680 [==============================] - 0s 235us/step - loss: 0.0062 - acc: 0.9985 - val_loss: 0.5961 - val_acc: 0.8667\n",
      "Epoch 78/100\n",
      "680/680 [==============================] - 0s 228us/step - loss: 0.0062 - acc: 0.9985 - val_loss: 0.6038 - val_acc: 0.8667\n",
      "Epoch 79/100\n",
      "680/680 [==============================] - 0s 309us/step - loss: 0.0061 - acc: 0.9985 - val_loss: 0.6053 - val_acc: 0.8667\n",
      "Epoch 80/100\n",
      "680/680 [==============================] - 0s 274us/step - loss: 0.0061 - acc: 0.9985 - val_loss: 0.6203 - val_acc: 0.8667\n",
      "Epoch 81/100\n",
      "680/680 [==============================] - 0s 309us/step - loss: 0.0060 - acc: 0.9985 - val_loss: 0.6211 - val_acc: 0.8667\n",
      "Epoch 82/100\n",
      "680/680 [==============================] - 0s 308us/step - loss: 0.0060 - acc: 0.9985 - val_loss: 0.6320 - val_acc: 0.8667\n",
      "Epoch 83/100\n",
      "680/680 [==============================] - 0s 235us/step - loss: 0.0059 - acc: 0.9985 - val_loss: 0.6343 - val_acc: 0.8667\n",
      "Epoch 84/100\n",
      "680/680 [==============================] - 0s 258us/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.6405 - val_acc: 0.8667\n",
      "Epoch 85/100\n",
      "680/680 [==============================] - 0s 343us/step - loss: 0.0058 - acc: 0.9985 - val_loss: 0.6432 - val_acc: 0.8667\n",
      "Epoch 86/100\n",
      "680/680 [==============================] - 0s 302us/step - loss: 0.0058 - acc: 0.9985 - val_loss: 0.6510 - val_acc: 0.8667\n",
      "Epoch 87/100\n",
      "680/680 [==============================] - 0s 230us/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.6560 - val_acc: 0.8667\n",
      "Epoch 88/100\n",
      "680/680 [==============================] - 0s 241us/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.6637 - val_acc: 0.8667\n",
      "Epoch 89/100\n",
      "680/680 [==============================] - 0s 269us/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.6728 - val_acc: 0.8667\n",
      "Epoch 90/100\n",
      "680/680 [==============================] - 0s 262us/step - loss: 0.0056 - acc: 0.9985 - val_loss: 0.6766 - val_acc: 0.8583\n",
      "Epoch 91/100\n",
      "680/680 [==============================] - 0s 233us/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.6800 - val_acc: 0.8583\n",
      "Epoch 92/100\n",
      "680/680 [==============================] - 0s 235us/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.6805 - val_acc: 0.8583\n",
      "Epoch 93/100\n",
      "680/680 [==============================] - 0s 235us/step - loss: 0.0054 - acc: 0.9985 - val_loss: 0.6930 - val_acc: 0.8583\n",
      "Epoch 94/100\n",
      "680/680 [==============================] - 0s 238us/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.6976 - val_acc: 0.8583\n",
      "Epoch 95/100\n",
      "680/680 [==============================] - 0s 243us/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.7002 - val_acc: 0.8583\n",
      "Epoch 96/100\n",
      "680/680 [==============================] - 0s 246us/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.7064 - val_acc: 0.8583\n",
      "Epoch 97/100\n",
      "680/680 [==============================] - 0s 275us/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.7156 - val_acc: 0.8583\n",
      "Epoch 98/100\n",
      "680/680 [==============================] - 0s 308us/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.7207 - val_acc: 0.8583\n",
      "Epoch 99/100\n",
      "680/680 [==============================] - 0s 303us/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.7202 - val_acc: 0.8583\n",
      "Epoch 100/100\n",
      "680/680 [==============================] - 0s 287us/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.7301 - val_acc: 0.8583\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not numpy.float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-336-c6d57fc36bab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_accuracy:\"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_accuracy:\"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not numpy.float64"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs = 100,validation_split= 0.15,batch_size=10)\n",
    "loss,accuracy = model.evaluate(X_train,y_train,verbose =False)\n",
    "print(\"train_accuracy:\" +accuracy)\n",
    "loss,accuracy = model.evaluate(X_test,y_test,verbose =False)\n",
    "print(\"test_accuracy:\" +accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1,len(acc)+1)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(x,acc,'b',label= 'training_acc')\n",
    "    plt.plot(x,val_acc,'r',label= 'val_acc')\n",
    "    plt.title(\"training and val acc\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(x,loss,'b',label= 'training_loss')\n",
    "    plt.plot(x,val_loss,'r',label= 'val_loss')\n",
    "    plt.title(\"training and val loss\")\n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = imdb_df['sentence'].values\n",
    "y = imdb_df['label'].values\n",
    "sents_train, sents_test,y_train,y_test = tts(sents,y,test_size = 0.25,random_state = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 5000)\n",
    "tokenizer.fit_on_texts(sents_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(sents_train)\n",
    "X_test = tokenizer.texts_to_sequences(sents_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 1000\n",
    "X_train = pad_sequences(X_train,padding ='post',maxlen = maxlen)\n",
    "X_test = pad_sequences(X_test,padding ='post',maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 64  35 123   3 315 409   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "model = Sequential(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 1000, 50)          132500    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                500010    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 632,521\n",
      "Trainable params: 632,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Embedding(input_dim=vocab_size,output_dim= embedding_dim,input_length = maxlen))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer = 'adam',loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6977 - acc: 0.4693 - val_loss: 0.6932 - val_acc: 0.4480\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6931 - acc: 0.5173 - val_loss: 0.6936 - val_acc: 0.4480\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6930 - acc: 0.5173 - val_loss: 0.6941 - val_acc: 0.4480\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6929 - acc: 0.5173 - val_loss: 0.6943 - val_acc: 0.4480\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6929 - acc: 0.5173 - val_loss: 0.6947 - val_acc: 0.4480\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6928 - acc: 0.5173 - val_loss: 0.6950 - val_acc: 0.4480\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6927 - acc: 0.5173 - val_loss: 0.6951 - val_acc: 0.4480\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6927 - acc: 0.5173 - val_loss: 0.6953 - val_acc: 0.4480\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6927 - acc: 0.5173 - val_loss: 0.6956 - val_acc: 0.4480\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6927 - acc: 0.5173 - val_loss: 0.6956 - val_acc: 0.4480\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6927 - acc: 0.5173 - val_loss: 0.6961 - val_acc: 0.4480\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6961 - val_acc: 0.4480\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6963 - val_acc: 0.4480\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6965 - val_acc: 0.4480\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6966 - val_acc: 0.4480\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6966 - val_acc: 0.4480\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6927 - acc: 0.5173 - val_loss: 0.6966 - val_acc: 0.4480\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6968 - val_acc: 0.4480\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6966 - val_acc: 0.4480\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6969 - val_acc: 0.4480\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6968 - val_acc: 0.4480\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6969 - val_acc: 0.4480\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6969 - val_acc: 0.4480\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6969 - val_acc: 0.4480\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6969 - val_acc: 0.4480\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6927 - acc: 0.5173 - val_loss: 0.6973 - val_acc: 0.4480\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6972 - val_acc: 0.4480\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6972 - val_acc: 0.4480\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6972 - val_acc: 0.4480\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6974 - val_acc: 0.4480\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6973 - val_acc: 0.4480\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6927 - acc: 0.5173 - val_loss: 0.6974 - val_acc: 0.4480\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6973 - val_acc: 0.4480\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6974 - val_acc: 0.4480\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6972 - val_acc: 0.4480\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6973 - val_acc: 0.4480\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6973 - val_acc: 0.4480\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6972 - val_acc: 0.4480\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6972 - val_acc: 0.4480\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6972 - val_acc: 0.4480\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6975 - val_acc: 0.4480\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6974 - val_acc: 0.4480\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6973 - val_acc: 0.4480\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6973 - val_acc: 0.4480\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6974 - val_acc: 0.4480\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6927 - acc: 0.5173 - val_loss: 0.6974 - val_acc: 0.4480\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5173 - val_loss: 0.6974 - val_acc: 0.4480\n",
      "Epoch 48/100\n",
      "540/750 [====================>.........] - ETA: 0s - loss: 0.6936 - acc: 0.5037"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-350-6dc8887e975a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 100,validation_data=(X_test,y_test),batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, GlobalMaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 1000, 100)         265000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 996, 128)          64128     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 330,429\n",
      "Trainable params: 330,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/10\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 9.6466e-04 - acc: 1.0000 - val_loss: 0.7232 - val_acc: 0.7480\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 7.5496e-04 - acc: 1.0000 - val_loss: 0.7379 - val_acc: 0.7480\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 6.0552e-04 - acc: 1.0000 - val_loss: 0.7509 - val_acc: 0.748004 - acc: \n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 5.0081e-04 - acc: 1.0000 - val_loss: 0.7636 - val_acc: 0.7480\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 4.1580e-04 - acc: 1.0000 - val_loss: 0.7746 - val_acc: 0.7480\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 3.5080e-04 - acc: 1.0000 - val_loss: 0.7858 - val_acc: 0.7480\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 3.0060e-04 - acc: 1.0000 - val_loss: 0.7958 - val_acc: 0.7480\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 2.6087e-04 - acc: 1.0000 - val_loss: 0.8052 - val_acc: 0.7480\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 2.2709e-04 - acc: 1.0000 - val_loss: 0.8139 - val_acc: 0.7480\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 1.9900e-04 - acc: 1.0000 - val_loss: 0.8231 - val_acc: 0.7520\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,epochs = 10,validation_data=(X_test,y_test),batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str, not numpy.float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-358-ef9e75cb0189>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_accuracy:\"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_accuracy:\"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not numpy.float64"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_train,y_train,verbose =False)\n",
    "print(\"train_accuracy:\" +accuracy)\n",
    "loss,accuracy = model.evaluate(X_test,y_test,verbose =False)\n",
    "print(\"test_accuracy:\" +accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
